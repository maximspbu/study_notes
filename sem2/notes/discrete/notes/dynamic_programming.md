---
layout: default
---
# Динамическое программирование.

<aside>
❗ Динамическое программирование (ДП) – методика решения поставленной задачи путем комбинирования решений вспомогательных задач.

</aside>

<aside>
❗ Метод разбиения (декомпозиции, ”разделяй и властвуй”):

1. Задача разбивается на более мелкие вспомогательные задачи
2. Эти вспомогательные задачи рекурсивно решаются
3. Их решения комбинируются и образуют решение исходной задачи
</aside>

Примерами метода разбиения являются большое количество сортировок, алгоритмы перемножения больших чисел, важнейшего алгоритма быстрого преобразования Фурье, вычисления дискретного преобразования Фурье.

<aside>
❗ Жадные алгоритмы: на каждом очередном шаге совершается выбор,
который кажется самым оптимальным в данный момент.

</aside>

Примерами жадных алгоритмов являются алгоритмы Краскала, Прима-Ярника.

<aside>
❗ Этапы алгоритма ДП:

1. Описание структуры оптимального решения
2. Рекурсивное определение значения, соответствующего оптимальному решению
3. Вычисление значения, соответствующего оптимальному решению, с помощью метода восходящего анализа
4. Составление оптимального решения на основе информации, полученной на предыдущих этапах (составлять оптимальное решение нужно не во всех задачах; если все же требуется, то на шаге 3 вводится дополнительная структура для хранения информации)
</aside>

Отличие парадигм ДП и “разделяй и властвуй”

| ДП | Разделяй и властвуй |
| --- | --- |
| По-разному определяет способы разделения входной
задачи на мелкие подзадачи. | Рекурсивные вызовы в методе
разбиения придерживаются одного способа разделения входа на вспомогательные задачи. |
| Поскольку способы разделения различны, то вспомогательные
задачи зачастую повторяются. Поэтому для оптимизации их решения кэшируются в специальных структурах (очень часто это таблицы). | В методе разбиения вспомогательные задачи не пересекаются и кэширование их решения не нужно. |
| Обычно понижение в сложности, которое получается заменой
условного ”простого” алгоритма, заметнее в случае ДП. | Понижение сложности в данной парадигме менее заметно. |
| В алгоритмах ДП размеры вспомогательных задач могут едва отличаться. | Обычно в методе разбиения размеры вспомогательных задач кратно меньше размеры входной задачи. |

<aside>
❗ Ключевые свойства, которые должны быть у задачи оптимизации:

1. Наличие оптимальной подструктуры.
2. Перекрывающиеся вспомогательные программы.
</aside>

<aside>
❗ Принцип оптимальности Беллмана, или наличие оптимальной структуры, заключается в том, что в оптимальном решении задачи оптимизации содержатся оптимальные решения вспомогательных подзадач.

</aside>

Наличие оптимальной подструктуры роднит ДП с жадным подходом, в
котором ее наличие тоже необходимо.

<aside>
❗ Отличия в направлении использования использования оптимальной подструктуры:

В ДП используется в восходящем направлении: из решения
вспомогательных задач конструируется решение исходной –
движение ”снизу вверх”.
В жадных алгоритмах движение по нисходящей: вместо выбора из
нескольких решений выбирается кажущийся оптимальным на данный
момент, а потом уже решается возникшая в результате выбора
вспомогательная задача – движение ”сверху вниз”.

</aside>

Поговорим о перекрывающихся вспомогательных задачах: пространство вспомогательных задач должно быть небольшим (обычно это полиномиальная функция от размера входных данных) в том смысле, что в результате выполнения рекурсивного алгоритма одни и те же вспомогательные задачи решаются снова и снова (возникают в процессе решения задачи в разных подзадачах и в этом смысле перекрываются), а новые вспомогательные задачи не возникают.

Такое количество все же ведет к корректному решению задачи и позволяет ускорить решение в сравнение с условным ”простым” решением;

Каждая вспомогательная задача решается ровно один раз, после чего ее решение записывается в специальную таблицу. Из этой таблицы данные уже потом извлекаются за константное время.

Примерами перекрываемости являются сортировка слиянием, вычисление чисел Фибоначчи. 

<aside>
❗ Процесс сохранения результатов вызова функции на определенных параметрах для предотвращения повторных вызовов называется мемоизацией или запоминанием.

</aside>

### Задача о минимальном размене.

Имеется некоторая сумма $N\in\N$, которую необходимо разменять наименьшим количеством монет номиналами $\set{w_i}_{i=1}^k$, где $w_i\in \N$.

Покажем наличие оптимальной структуры:

Рассмотрим оптимальный размен $\set{x_i}_{i=1}^k$ ($x_i~-~$число монет с номиналом $w_i$) монетами $\set{w_i}_{i=1}^k$ суммы $N$. Возьмём его разбиение на $2$ группы монет: $\set{\overline{x}_i}_{i=1}^k$ и $\set{x_i-\overline{x}_i}_{i=1}^k$.

$$
b=\displaystyle\sum_{i=1}^k\overline{x}_i w_i~\text{ и }~N-b=\displaystyle\sum_{i=1}^k(x_i-\overline{x}_i)w_i,\text{ где } 0\le\overline{x_i}\le x_i.
$$

<aside>
❓ Тогда $\set{\overline{x}_i}_{i=1}^k~-~$оптимальный размен суммы $b$, а $\set{x_i-\overline{x}_i}_{i=1}^k~-~$суммы $N-b$.

</aside>

<aside>
<img src="https://www.notion.so/icons/triangle-alternate_gray.svg" alt="https://www.notion.so/icons/triangle-alternate_gray.svg" width="40px" /> Предположим, что $\set{x_i^*}_{i=1}^k~-~$более оптимальный способ разменять сумму $b$, то есть верно $\displaystyle\sum_{i=1}^k x^*_i < \sum_{i=1}^k\overline{x}_i$ и $\displaystyle\sum_{i=1}^k x^*_iw_i=b$.

Тогда 
$\displaystyle\sum_{i=1}^k x^*_iw_i+\sum_{i=1}^k(x_i-\overline{x}_i)w_i=N

\Rarr \displaystyle\sum_{i=1}^k x^*_i+(x_i-\overline{x}_i)<\sum_{i=1}^k x_i$  $(?!)$

</aside>

Обозначим $c[p]~-~$минимальное кол-во монет, необходимое для размена суммы $p$.
Заметим, что в оптимальном размене присутствует монета номинала $w_i\le p$. Тогда оставшиеся монеты, должны оптимально менять сумму $p-w_i$, то есть $c[p]=c[p-w_i]+1$.

В общем случае, мы не знаем, какой номинал входит в оптимальный размен, и поэтому проверяем все $w_i\le p$ и берем минимум из $c[p-w_i]$.

Составляем рекурсивное соотношение:

$$
c[p]=\begin{cases}
0,&\text{если }p=0
\\
\displaystyle\min_{w_i\le p}(1+c[p-w_i]),&\text{если }p>0
\end{cases}
$$

<aside>
⚙ Найдём оптимальный размен:

$1)$ Инициализируем списки $c[0:N]$ и $s[0:N]$.

В $c$ хранится минимальное кол-во монет для размена каждой из сумм.
В $s$ хранится индекс первой монеты оптимального размена каждой суммы.

$2)$ Пробегаемся по всем возможным значениям суммы $l$ для размена.

Обновляем $c[l]$ значением $\displaystyle\min_{w_i<l}(1+c[l-w_i])$ и присваиваем $s[l]$ индекс монеты, на которой был достигнут минимум.

$3)$ После заполнения списков $c[N]$ будет равно искомому оптимуму.

</aside>

<aside>
⚙ Восстановим решение по списку $s$.

$1)$ Берем монету с индексом $s[N]$ и переходим к рассмотрению суммы $N-w_{s[N]}$.

$2)$ На промежуточном шаге берем монету с индексом $s[l]$ и смотрим $l-w_{s[l]}$.

$3)$ Выполняем шаг $2)$ пока сумма не станет равна $0$.

</aside>

### Задача о количестве разменов.

Дана сумма $N\in\N$ и номиналы монет $\set{w_i}_{i=1}^n$, где $w_i\in\N$. Необходимо подсчитать количество способов разменять сумму $N$ монетами $\set{w_i}_{i=1}^n$.

Пусть $h[k,v]~-~$количество разменов суммы $v$ монетами с номиналами $\set{w_i}_{i=1}^k$, которые отсортированы по возрастанию. Тогда рекурсивное отношение можно построить основываясь на том, что монеты можно разбить на $2$ множества: содержащие старший номинал и не содержащие.

Тогда справедливо следующее рекурсивное отношение:

$$
h[k,v]=\begin{cases}
h[k-1,v]+h[k,v-w_k],&\text{если }v\ge w_k
\\
h[k-1,v],&\text{если }v<w_k
\end{cases}
$$

При этом нужно учитывать граничные условия:

- Если сумма равна $0$, то есть ровно один вариант её размена $(x_i=0)$
- Если сумма $v\ne0$, то $h[0,v]=0$ (сумма $v$ не разменивается $0$ монет).

Значение $h[n,N]$ равно искомому кол-ву разменов $N$ всеми возможными монетами.

<aside>
🔑 Пример решения задачи:

![Untitled](sem2/notes/discrete/notes/dynamic_programming/Untitled.png)

</aside>

### Второе решение задачи о минимальном размене.

Пусть $S_{k,v}~-~$минимальный размен суммы $v$ монетами $\set{w_i}_{i=1}^k$.

Как и в задаче о количестве разменов есть $2$ случая:

$1)$ $w_k\notin S_{k,v}$
В этом случае $|S_{k,v}|=|S_{k-1,v}|$, так как если $|S_{k,v}|>|S_{k-1,v}|$, то $S_{k-1,v}$ подходит для размена $v$ на монеты $\set{w_i}_{i=1}^k$ $(?!$ с оптимальностью $S_{k,v})$, и если $|S_{k,v}|<|S_{k-1,v}|$, то $S_{k,v}$ подходит для размена $v$ на монеты $\set{w_i}_{i=1}^{k-1}$ $(?!$ с оптимальностью $S_{k-1,v})$.

$2)~w_k\in S_{k,v}$
Тогда оптимальный размен $S_{k,v-w_k}$ содержит ровно на одну монету меньше, иначе получим противоречие с оптимальностью $S_{k,v}$ либо $S_{k,v-w_k}$.

Так как заранее мы не можем узнать, будет ли $w_k\in S_{k,v}$, нужно взять наименьшее по мощности из $S_{k-1,v}$ и $S_{k,v-w_k}\cup{w_k}$.

Введем $c[k,v]=|S_{k,v}|$. Тогда, если $w_k<v$, то $c[k,v]=c[k-1,v]$, и если $w_k>v$, то нужно выбрать минимум из $c[k-1,v]$ и $c[k,v-w_k]+1$.

Таким образом, получилось следующее рекурсивное соотношение:

$$
\begin{cases}
c[k,v]=
\begin{cases}
c[k-1,v],&\text{если }w_k>v
\\
\min(c[k-1,v],c[k,v-w_k]+1),&\text{если }w_k\le v
\end{cases}
\\
c[0,v]=+\infty
\\
c[k,0]=0
\end{cases}
$$

<aside>
⚙ Приведем алгоритм нахождения размена:

$1)$ Инициализируем таблицу $c[n,N]$ нулями.

$2)$ На каждом шаге добавляем в рассмотрение монету и проводим пересчет значений в $i$-том ряду.

$3)$ Принцип заполнения $c[i,v]$ следующий:

Если $v<w_i$, то $c[i,v]=c[i-1,v]$ и переходим в соседнюю клетку.

Если $v\ge w_i$, то $c[i,v]=\min(c[i-1,v],c[i,v-w_i]+1)$

$4)$ Переходим к заполнению следующей строки.

</aside>

После заполнения таблицы ответ будет находиться в $c[n,N]$.

<aside>
🔑 Пример применения алгоритма:

![Untitled](sem2/notes/discrete/notes/dynamic_programming/Untitled%201.png)

</aside>

### Задача о бродячем торговце.

Есть взвешенный полной неорграф из $N$ вершин. Требуется найти гамильтонов цикл наименьшего веса.

Оптимальное решение можно рассматривать как путь, начинающийся в произвольной вершине $v_0$ (так как гамильтонов цикл содержит все вершины и неважно из какой стартовать) и заканчивающийся в ней же.

Обозначим за $D(S,v)~-~$длина кратчайшего пути, начинающегося в $v_0$, проходящего через вершины множества $S$ и заканчивающегося в вершине $v$.

Тогда кратчайший путь будет состоять из двух частей:

1. Какое-то ребро из $w\in S$ в конечную вершину $v$.
2. Кратчайший путь из $v_0$ в $w$, проходящий через все вершины $S\setminus{\set{v}}$.

Покажем оптимальную структуру:

Заранее узнать, какой будет вершина $w$ не получится, и поэтому нужно посмотреть все ребра $w$ смежные с конечной вершиной $v$, а затем для них решить ту же задачу, то есть найти $D(S\setminus\set{v},w)$.

Тогда запишем рекурсивное со отношение:

$$
D(S,v)=\begin{cases}
c(v_0,v),&\text{если }S=\set{v}
\\
+\infty,&\text{если }v\notin S
\\
\displaystyle\min_{w\in S\setminus\set{v}}\big(D(S\setminus\set{v},w\big)+c(w,v),&\text{иначе}
\end{cases}
$$

<aside>
⚙ Алгоритм вычисления ответа.

$1)$ Зададим произвольную вершину $v_0$ и инициализириуем матрицу $D$ размерами $2^n\times n$ значениями $+\infty$ (это будут длины кратчайших путей).

Также зададим матрицу $P$ размера $2^n\times n$, в которой будем хранить последнее ребро кратчайшего пути.

$2)$ Изначально в $D[\set{v},v]$ записываем значения $c(v_0,v)$.

$3)$ Итерируемся по всем возможным размерам подмножества вершин $S$ и рассматриваем каждое из них.

Для каждой в вершины $v$ в подмножестве находим $D(S,v)$ и сохраняем вершину $w$, на которой был достигнут результат, в $P[S,v]$.

$4)$ Заполнив матрицы $D$ и $P$, составим оптимальный обход.

Первой вершиной будет $P[V,v_0]\setminus{\set{v_0}}=:v_1$, затем $P\big[V\setminus\set{v_1},v_1\big]\setminus\set{v_1}$ и так далее.

Чтобы получить стоимость поездки, нужно просто складывать веса ребер при обходе.

</aside>

<aside>
🔑 Пример задачи о бродячем торговце.

![Untitled](sem2/notes/discrete/notes/dynamic_programming/Untitled%202.png)

![Untitled](sem2/notes/discrete/notes/dynamic_programming/Untitled%203.png)

</aside>